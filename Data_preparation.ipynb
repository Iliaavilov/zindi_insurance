{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                          0\n",
       "join_date                   2\n",
       "sex                         0\n",
       "marital_status              0\n",
       "birth_year                  0\n",
       "branch_code                 0\n",
       "occupation_code             0\n",
       "occupation_category_code    0\n",
       "P5DA                        0\n",
       "RIBP                        0\n",
       "8NN1                        0\n",
       "7POT                        0\n",
       "66FJ                        0\n",
       "GYSR                        0\n",
       "SOP4                        0\n",
       "RVSZ                        0\n",
       "PYUQ                        0\n",
       "LJR9                        0\n",
       "N2MW                        0\n",
       "AHXO                        0\n",
       "BSTQ                        0\n",
       "FM3X                        0\n",
       "K6QO                        0\n",
       "QBOL                        0\n",
       "JWFN                        0\n",
       "JZ9D                        0\n",
       "J9JW                        0\n",
       "GHYX                        0\n",
       "ECY3                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                          0\n",
       "join_date                   1\n",
       "sex                         0\n",
       "marital_status              0\n",
       "birth_year                  0\n",
       "branch_code                 0\n",
       "occupation_code             0\n",
       "occupation_category_code    0\n",
       "P5DA                        0\n",
       "RIBP                        0\n",
       "8NN1                        0\n",
       "7POT                        0\n",
       "66FJ                        0\n",
       "GYSR                        0\n",
       "SOP4                        0\n",
       "RVSZ                        0\n",
       "PYUQ                        0\n",
       "LJR9                        0\n",
       "N2MW                        0\n",
       "AHXO                        0\n",
       "BSTQ                        0\n",
       "FM3X                        0\n",
       "K6QO                        0\n",
       "QBOL                        0\n",
       "JWFN                        0\n",
       "JZ9D                        0\n",
       "J9JW                        0\n",
       "GHYX                        0\n",
       "ECY3                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим из тренировочных данных пропуски, а в тестовом датафрейме заменим пропущенные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "test['join_date'] = test['join_date'].fillna('1/1/2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тестовых данных вместо f проставлены F в marital status, приведем данные к одному формату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['marital_status'] = train['marital_status'].replace('f', 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Трансформируем дату в timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranforming_date(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Трансформирует датафрейм с заданной колонкой в unix timestamp\n",
    "\n",
    "    ----------\n",
    "    X_train - тренировочные данные\n",
    "    y_train - тренировочный target\n",
    "    X_test - тестовые данные\n",
    "    model - модель с заданными параметрами\n",
    "    ID_X_Var - датафрейм с ID пользователя и товара\n",
    "    ----------\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data['join_date'] = pd.to_datetime(data['join_date'], dayfirst = True)\n",
    "    data['timestamp'] = data['join_date'].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = tranforming_date(train)\n",
    "test = tranforming_date(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['join_date'], axis = 'columns')\n",
    "test = test.drop(['join_date'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переведем target variables в строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем такой датафейм, в котором каждое наблюдение будет соотвествовать паре пользователь - продукт. Также оставим данные о наличии остальных продуктов у пользователя. \\\n",
    "Таким образом, мы сохраним информацию о наличии каждого продукта у пользователя и будем предсказывать для каждого наблюдения лишь наличие одного конкретного продукта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Список переменных, которые надо предсказать\n",
    "target_cols = ['P5DA', 'RIBP', '8NN1',\n",
    "               '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "               'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Переведем target variables в строки (широкий формат -> длинный формат)\n",
    "train = pd.merge(train.melt(id_vars = [col for col in train.columns if col not in target_cols], \n",
    "                            value_vars = target_cols, \n",
    "                            value_name = 'presence'), \n",
    "                 train[['ID', *target_cols]], \n",
    "                 on = 'ID')\n",
    "\n",
    "test = pd.merge(test.melt(id_vars = [col for col in test.columns if col not in target_cols], \n",
    "                          value_vars = target_cols, \n",
    "                          value_name = 'presence'), \n",
    "                 test[['ID', *target_cols]], \n",
    "                 on = 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кодирование переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code']\n",
    "\n",
    "def encoding(data_train, data_test, column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Кодировка колонки датафрейма через LabelEncoder из sklearn\n",
    "\n",
    "    ----------\n",
    "    data_train - тренировочный датафрейм\n",
    "    data_test - тестовый датафрейм\n",
    "    column - колонка датафрейма, которую надо закодировать\n",
    "    ----------\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.append(data_train[column].values, data_test[column].values))\n",
    "    data_train[column] = le.transform(data_train[column].values)\n",
    "    data_test[column] = le.transform(data_test[column].values)\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in cat_features:\n",
    "    train, test = encoding(train, test, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание тренировочного датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тестовом датасете у нас есть множество пользователей, для которых нужно предсказать информацию о наличии каждого продукта. При этом у нас уже есть информация о наличии некоторых товаров у некоторых пользователей. \\\n",
    "Нам надо собрать такой тренировочный датасет, который максимально \"повторит\" тестовый. \\\n",
    "Для каждого отдельного фолда и для каждой его части (тренировочная/тестовая) будем для каждого пользователя делать следующее:\n",
    "1. Выбираем все наблюдения для данного пользователя (то есть все пары пользователь - товар)\n",
    "2. Выбираем все товары, которые уже есть у пользователя\n",
    "3. Для каждого имеющегося товара создаем копию всех наблюдений пользователя, и удаляем из них информацию о наличии данного товара\n",
    "4. Собираем вместе все датафрейми с прошлого шага\n",
    "\n",
    "Таким образом, у нас получится датасет, в котором у нас будем информация о всех пользователях и наличии у них каждого товара. При этом мы искуственно \"размножим\" датасет поочередно убирая информацию о наличии у пользователя каждого товара и собирая вместе все эти датафреймы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaping(user_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Создает для пользователя все возможные комбинации, имеющихся у него товаров\n",
    "\n",
    "    ----------\n",
    "    user_data - данные о пользователе\n",
    "    ----------\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    new_user_data = pd.DataFrame() # Датафрейм с новой информацией о пользователе\n",
    "    user_data = user_data.reset_index(drop = True)\n",
    "    #Выбираем все товары,которые есть у пользователя\n",
    "    presence_1_vars = user_data[user_data['presence'] == 1]['variable'].values\n",
    "    \n",
    "    for var in presence_1_vars:\n",
    "        temp_user_data = user_data.copy() # Копируем изначальные данные о пользователе\n",
    "        temp_user_data[var] = 0 # Убираем информацию о наличии товара у пользователя\n",
    "        new_user_data = new_user_data.append(temp_user_data, ignore_index = True)\n",
    "    \n",
    "    return(new_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.groupby('ID').apply(reshaping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраним данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_prepared.csv', index = False)\n",
    "test.to_csv('test_prepared.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
