{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from typing import Iterable\n",
    "from itertools import chain\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark import SparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").config(\"spark.driver.cores\", 16).appName('zindi-insurance').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://DESKTOP-NLTNIOI:4040'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.uiWebUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = spark.read.csv('Train.csv', header = True)\n",
    "test = spark.read.csv('Test.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset = 'join_date')\n",
    "test = test.fillna('1/1/2018', subset = 'join_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('marital_status', regexp_replace('marital_status', 'f', 'F'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Трансформируем дату в timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.withColumn('join_date', to_timestamp('join_date', 'd/M/y'))\n",
    "test = test.withColumn('join_date', to_timestamp('join_date', 'd/M/y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('join_date', unix_timestamp('join_date', 'd/M/y'))\n",
    "test = test.withColumn('join_date', unix_timestamp('join_date', 'd/M/y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переведем target variables в строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['P5DA', 'RIBP', '8NN1',\n",
    "           '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "           'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt(\n",
    "        df, \n",
    "        id_vars, \n",
    "        value_vars, \n",
    "        var_name = 'variable',\n",
    "        value_name = 'value'):\n",
    "    \"\"\"Convert :class:`DataFrame` from wide to long format.\"\"\"\n",
    "\n",
    "    # Create map<key: value>\n",
    "    _vars_and_vals = create_map(\n",
    "        list(chain.from_iterable([\n",
    "            [lit(c), col(c)] for c in value_vars]\n",
    "        ))\n",
    "    )\n",
    "\n",
    "    _tmp = df.select(*id_vars, explode(_vars_and_vals)) \\\n",
    "        .withColumnRenamed('key', var_name) \\\n",
    "        .withColumnRenamed('value', value_name)\n",
    "\n",
    "    return _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_vars = train[['ID', *target_cols]]\n",
    "test_id_vars = test[['ID', *target_cols]]\n",
    "\n",
    "train = melt(train, \n",
    "             id_vars = [col for col in train.columns if col not in target_cols], \n",
    "             value_vars = target_cols, value_name = 'presence')\n",
    "test = melt(test, \n",
    "            id_vars = [col for col in test.columns if col not in target_cols], \n",
    "            value_vars = target_cols, value_name = 'presence')\n",
    "\n",
    "train = train.join(train_id_vars, on = 'ID')\n",
    "test = test.join(test_id_vars, on = 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кодирование переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(train, test, column):\n",
    "    indexer = StringIndexer(inputCol = column, outputCol = '{}_indexed'.format(column))\n",
    "    indexer = indexer.fit(train.union(test))\n",
    "\n",
    "\n",
    "    train = indexer.transform(train)\n",
    "    train = train.drop(column)\n",
    "    train = train.withColumnRenamed('{}_indexed'.format(column), column)\n",
    "\n",
    "\n",
    "    test = indexer.transform(test)\n",
    "    test = test.drop(column)\n",
    "    test = test.withColumnRenamed('{}_indexed'.format(column), column)\n",
    "    \n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cat_features:\n",
    "    \n",
    "    train, test = encoding(train, test, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание тренировочного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaping(user_data):\n",
    "    \n",
    "    new_user_data = pd.DataFrame()\n",
    "    presence_1_vars = user_data[user_data['presence'] == '1']['variable'].values\n",
    "    \n",
    "    for var in presence_1_vars:\n",
    "            \n",
    "        temp_user_data = user_data.copy()\n",
    "        temp_user_data[var] = '0'\n",
    "        new_user_data = new_user_data.append(temp_user_data)\n",
    "    \n",
    "    return(new_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.groupby('ID').applyInPandas(reshaping, schema = train.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраним данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.toPandas().to_csv('train_prepared.csv', index = False)\n",
    "test.toPandas().to_csv('test_prepared.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
